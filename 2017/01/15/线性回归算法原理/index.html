<!DOCTYPE html>
<html>
  <!DOCTYPE html>
<html lang="zh-Hans">
<link rel="stylesheet" href="https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.css">

<script src="https://cdn.staticfile.org/jquery/1.10.2/jquery.min.js"></script>
<script src="//lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.js"> </script>

<head>
  <meta http-equiv="content-type" content="text/html; charset=utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=Edge,chrome=1">
  
  <title>线性回归算法原理 - July</title>
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0">
  
  <meta name="keywords" content=>
  
    <meta name="description" content="每天进步一点点">
  
  
    <link rel="shortcut icon" type="image/x-icon" href="/images/icon/football2.png?v=1.02">
  
  
    <link rel="alternate" href="/atom.xml " title="July" type="application/atom+xml">
  

  
<script src="/js/fancybox.js"></script>


  
<link rel="stylesheet" href="/css/style.css">


<meta name="generator" content="Hexo 5.3.0"></head>
  <body>
    <div class="container">
      
<header class="header">
  <div class="blog-title">
    <a href="/" class="logo">July</a>
    <div class="subtitle">life feeds on negative entropy.</div>
  </div>
  <nav class="navbar">
    <ul class="menu">
      
        <li class="menu-item">
          <a href="/" class="menu-item-link">主页</a>
        </li>
      
        <li class="menu-item">
          <a href="/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD" class="menu-item-link">人工智能</a>
        </li>
      
        <li class="menu-item">
          <a href="/categories/%E6%88%91%E7%9A%84%E4%B9%A6%E5%8D%95" class="menu-item-link">我的书单</a>
        </li>
      
        <li class="menu-item">
          <a href="/categories/%E7%94%9F%E6%B4%BB%E9%9A%8F%E7%AC%94" class="menu-item-link">生活随笔</a>
        </li>
      
        <li class="menu-item">
          <a href="/about" class="menu-item-link">关于</a>
        </li>
      
    </ul>
  </nav>

</header>


<article class="post">
  <h1 class="article-title"></h1>
  <div class="post-title">
    <h1 class="file-title">线性回归算法原理</h1>
  </div>
   
  <div class="post-content">
    <h1 id="1-问题引入"><a href="#1-问题引入" class="headerlink" title="1. 问题引入"></a>1. 问题引入</h1><p>&ensp;&ensp;&ensp;&ensp;回归分析是一种预测性建模技术，主要用来研究因变量$y_i$和自变量$x_i$之间的关系，通常被用于预测分析、时间序列等。</p>
<p>&ensp;&ensp;&ensp;&ensp;假设特征和结果满足线性关系，则线性回归的目标就是用一条直线去拟合样本点，当新的样本数据进来时，根据拟合的直线去预测新样本的结果。</p>
<h1 id="2-线性回归模型"><a href="#2-线性回归模型" class="headerlink" title="2. 线性回归模型"></a>2. 线性回归模型</h1><h2 id="2-1-模型建立"><a href="#2-1-模型建立" class="headerlink" title="2.1 模型建立"></a>2.1 模型建立</h2><p>&ensp;&ensp;&ensp;&ensp;假设南京的房价与房屋的特征满足线性回归模型，我们用$x(1),x(2),…x(N)$表示影响房子价格的特征因素，如面积、房子朝向、地理位置等，房子价格为$h(x)$，是一个由变量$x_i$共同决定的函数，由于不同的因素对房屋价格的影响程度是不同的，所以给每项特征因素赋予一个权重$w(j)$，则得到因变量与自变量之间的函数表达式：</p>
<script type="math/tex; mode=display">h\left ( x \right ) =w_{1}x^{\left ( 1 \right ) } +w_{2}x^{\left ( 2 \right ) }+...+w_{N}x^{\left ( N \right ) } + b</script><p>写成矩阵的形式，即向量$w=\left ( w_1,w_2,…w_n \right ) $是由各个向量权重组成的，向量$x=\left (x ^{\left ( 1 \right ) } ,x ^{\left ( 2 \right ) },…,x ^{\left ( N \right ) } \right ) $是某个样本数据的特征向量；$b$为偏置常数，则：</p>
<script type="math/tex; mode=display">h\left ( x \right ) =wx+b</script><p>那么机器学习的任务就是从过去的经验数据中，学习权重系数$w$和偏置常数$b$的最优值，使得回归模型对房子价格预测最准。</p>
<h2 id="2-2-学习策略"><a href="#2-2-学习策略" class="headerlink" title="2.2 学习策略"></a>2.2 学习策略</h2><p>&ensp;&ensp;&ensp;&ensp;选择合适的策略来学习最优的权重系数$w$和偏置常数$b$。对于回归问题，我们可以使用最小均方误差损失来描述模型的好坏：</p>
<script type="math/tex; mode=display">L\left ( w,b \right ) =\frac{1}{2} \sum_{i=1}^{M}\left [ h\left ( x_{i};w;b \right ) -y_{i} \right ]^{2}</script><p>其中$ h\left ( x_{i};w;b \right )$是对样本数据$x_{i}$的预测值，$y_{i}$是样本数据$x_{i}$的真实值，样本总数为$M$，$w$是各个特征权重组成的向量，$b$是偏置常数。</p>
<p>当上面的损失函数$L(w,b)$取最小值时，意味着所有样本的预测值和实际值之间的差距是最小的，这时候相当于我们模型的预测效果是最好的。</p>
<p>所以我们的策略就是最小化上面的损失函数：</p>
<script type="math/tex; mode=display">\min_{w,b}L\left ( w,b \right )  =\min_{w} \frac{1}{2} \sum_{i=1}^{M}\left [ h\left ( x_{i};w;b \right ) -y_{i} \right ]^{2}</script><p>通过求解上面的最优化问题，我们可以得到其中的待定参数$w_j$和偏置常数$b$的值。</p>
<h2 id="2-3-优化算法"><a href="#2-3-优化算法" class="headerlink" title="2.3 优化算法"></a>2.3 优化算法</h2><p>&ensp;&ensp;&ensp;&ensp;针对上述的优化问题，可以使用常用的梯度下降算法来求解，对损失函数求偏导：</p>
<script type="math/tex; mode=display">\begin{aligned}
\frac{\partial }{\partial w}L(w,b) &= \frac{\partial }{\partial w}  \left [ \frac{1}{2} \sum_{i=1}^{M} \left [ h\left ( x_i;w;b \right ) -y_i \right ]^2 \right ]\\ &=2\cdot \frac{1}{2}\cdot \left [ h\left ( x_i;w;b \right ) -y_i \right ]\cdot \frac{\partial }{\partial w} \left [ h\left ( x_i;w;b \right ) -y_i \right ]\\ &=\left ( wx_i+b-y_i \right )\cdot \frac{\partial }{\partial w} \left ( wx_i+b-y_i \right )\\ &=\left ( wx_i+b-y_i \right )x_i
\end{aligned}</script><script type="math/tex; mode=display">\begin{aligned}
\frac{\partial }{\partial b}L(w,b) &= \frac{\partial }{\partial b}\left [ \frac{1}{2}\sum_{i=1}^{M} \left [ h(x_i;w;b) -y_i \right ]^2   \right ]\\ &=2\cdot \frac{1}{2}\cdot \left [ h(x_i;w;b) -y_i\right ]\cdot \frac{\partial }{\partial b} \left [ h(x_i;w;b) -y_i \right ]\\ &= (wx_i+b-y_i)\cdot \frac{\partial }{\partial b}(wx_i+b-y_i)\\ &= (wx_i+b-y_i)
\end{aligned}</script><p>所以得到权重系数向量$w$和偏置常数$b$的更新公式为：</p>
<script type="math/tex; mode=display">\begin{aligned}
w\longleftarrow w-\eta \cdot \frac{\partial }{\partial w}L(w,b)  =w-\eta (wx_i+b-y_i)x_i
\end{aligned}</script><script type="math/tex; mode=display">
b\longleftarrow b-\eta \cdot \frac{\partial }{\partial b}L(w,b)  =b-\eta (wx_i+b-y_i)</script><p>其中$0&lt; \eta &lt;1$是学习率，这样通过迭代可以使损失函数以较快的速度不断减小，直到满足要求。</p>
<h1 id="3-算法流程与实现"><a href="#3-算法流程与实现" class="headerlink" title="3. 算法流程与实现"></a>3. 算法流程与实现</h1><h2 id="3-1-算法流程"><a href="#3-1-算法流程" class="headerlink" title="3.1 算法流程"></a>3.1 算法流程</h2><p>输入：训练集$T={(x_1,y_1),(x_2,y_2),…,(x_N,y_N)}$，学习率$\eta$。</p>
<p>输出：线性回归模型$h(x)=wx+b$；</p>
<p>步骤如下：</p>
<p>第1步：选取初始向量$w$和偏置常数$b$。</p>
<p>第2步：基于训练集进行参数更新:</p>
<script type="math/tex; mode=display">\begin{aligned}
w\longleftarrow w-\eta \cdot \frac{\partial }{\partial w}L(w,b)  =w-\eta (wx_i+b-y_i)x_i
\end{aligned}</script><script type="math/tex; mode=display">
b\longleftarrow b-\eta \cdot \frac{\partial }{\partial b}L(w,b)  =b-\eta (wx_i+b-y_i)</script><p>第3步：重复步骤2，直至模型满足训练要求。</p>
<h2 id="3-2-算法实现"><a href="#3-2-算法实现" class="headerlink" title="3.2 算法实现"></a>3.2 算法实现</h2><p><strong>任务描述：</strong></p>
<p>使用波士顿房价预测，波士顿房价数据与1978年开始统计，共包含506个样本数据点，每个样本都涵盖房屋的13种特征信息和对应的房屋价格，特征情况如下表所示：</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>特征值</th>
<th>特征说明</th>
</tr>
</thead>
<tbody>
<tr>
<td>ZN</td>
<td>住宅用地所占比例</td>
</tr>
<tr>
<td>INDUS</td>
<td>城镇中非商业用地所占比例</td>
</tr>
<tr>
<td>NOX</td>
<td>环保指标</td>
</tr>
<tr>
<td>RM</td>
<td>每栋住宅的房间数</td>
</tr>
<tr>
<td>AGE</td>
<td>1940年以前建成的自住单位比例</td>
</tr>
<tr>
<td>RAD</td>
<td>距离高速公路的便利指数</td>
</tr>
<tr>
<td>TAX</td>
<td>每一万美元的不动产税率</td>
</tr>
<tr>
<td>LSTAT</td>
<td>房东属于低收入阶层的比例</td>
</tr>
<tr>
<td>MEDV</td>
<td>自住房屋房价的中位数</td>
</tr>
<tr>
<td>…</td>
<td>…</td>
</tr>
</tbody>
</table>
</div>
<p><strong>代码实现：</strong><br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 1. 数据加载</span></span><br><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> load_boston</span><br><span class="line">boston = load_boston()</span><br><span class="line">X = boston.data</span><br><span class="line">y = boston.target</span><br><span class="line">print(X.shape)</span><br><span class="line">print(y.shape)</span><br><span class="line"><span class="comment"># 2. 划分数据集</span></span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line">X_train,X_test,y_train,y_test = train_test_split(X,y,train_size=<span class="number">0.7</span>)</span><br><span class="line"><span class="comment"># 3. 数据标准化</span></span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> preprocessing</span><br><span class="line">standard_X = preprocessing.StandardScaler()</span><br><span class="line">X_train = standard_X.fit_transform(X_train)</span><br><span class="line">X_test = standard_X.transform(X_test)</span><br><span class="line">standard_y = preprocessing.StandardScaler()</span><br><span class="line">y_train = standard_y.fit_transform(y_train.reshape(-<span class="number">1</span>,<span class="number">1</span>))</span><br><span class="line">y_test = standard_y.transform(y_test.reshape(-<span class="number">1</span>,<span class="number">1</span>))</span><br><span class="line"><span class="comment"># 4. 运用ElasticNet回归模型训练和预测</span></span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> ElasticNet</span><br><span class="line">ElasticNet_clf = ElasticNet(alpha=<span class="number">0.1</span>, l1_ratio=<span class="number">0.71</span>)</span><br><span class="line">ElasticNet_clf.fit(X_train, y_train.ravel())</span><br><span class="line">ElasticNet_clf_score = ElasticNet_clf.score(X_test, y_test.ravel())</span><br><span class="line">print(<span class="string">&#x27;lasso模型得分:&#x27;</span>, ElasticNet_clf_score)</span><br><span class="line">print(<span class="string">&#x27;特征权重:&#x27;</span>,ElasticNet_clf.coef_)</span><br><span class="line">print(<span class="string">&#x27;偏置值:&#x27;</span>,ElasticNet_clf.intercept_)</span><br><span class="line">print(<span class="string">&#x27;迭代次数:&#x27;</span>, ElasticNet_clf.n_iter_)</span><br><span class="line"><span class="comment"># 5. 画图</span></span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">fig = plt.figure(figsize=(<span class="number">20</span>,<span class="number">3</span>))</span><br><span class="line">axes = fig.add_subplot(<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>)</span><br><span class="line">line1, = axes.plot(<span class="built_in">range</span>(<span class="built_in">len</span>(y_test)), y_test, <span class="string">&#x27;b&#x27;</span>, label=<span class="string">&#x27;Actual_value&#x27;</span>)</span><br><span class="line">ElasticNet_clf_result = ElasticNet_clf.predict(X_test)</span><br><span class="line">line2, = axes.plot(<span class="built_in">range</span>(<span class="built_in">len</span>(ElasticNet_clf_result)), ElasticNet_clf_result, <span class="string">&#x27;r--&#x27;</span>, label=<span class="string">&#x27;ElasticNet_Predicted&#x27;</span>, linewidth = <span class="number">2</span>)</span><br><span class="line">axes.grid()</span><br><span class="line">fig.tight_layout()</span><br><span class="line">plt.legend(handles=[line1,line2])</span><br><span class="line">plt.title(<span class="string">&#x27;ElasticNet&#x27;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><br>预测结果：</p>
<p><img src="/images/AI/线性回归/Figure_1.png" alt=""></p>

  </div>
  <div class="post-footer">
    

    
      
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    tex2jax: {
      inlineMath: [ ['$','$'], ["\\(","\\)"] ],
      processEscapes: true,
      skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
    }
  });
  MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i=0; i < all.length; i += 1) {
        all[i].SourceElement().parentNode.className += ' has-jax';
    }
  });
</script>
<script type="text/javascript" src="http://mathjax.josephjctang.com/MathJax.js?config=TeX-MML-AM_HTMLorMML"></script>

    

    <a href="#top" class="top">Back to Top</a>
  </div>
</article>
<footer>
  &copy; 2017-2023
  <span class="author">
    July
  </span>
</footer>
    </div>
  </body>
</html>